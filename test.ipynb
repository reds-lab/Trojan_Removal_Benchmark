{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poison_methods import *\n",
    "import torch\n",
    "import torchshow as ts\n",
    "from torchvision import transforms\n",
    "from util import *\n",
    "import timm\n",
    "import copy\n",
    "import imageio as iio\n",
    "import torchvision\n",
    "from models import *\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PubFig_all2all():\n",
    "  badnets = BadNets()\n",
    "  \n",
    "  def label_poi(label):\n",
    "      return change_label_all2all(label, num_classes=83)  \n",
    "  \n",
    "  test_transform = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "\n",
    "  poison_method = ((badnets.img_poi, None), label_poi)\n",
    "  val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/base_line/data/pubfig.npy', test_transform, poison_method, -1)\n",
    "  \n",
    "  model = get_model(\"vit_tiny\", '/home/minzhou/public_html/backdoor_compet/base_line/checkpoint/pubfig_vittiny_all2all.pth', num_classes = test_dataset.num_classes, device = \"cuda:0\")\n",
    "\n",
    "  return val_dataset, test_dataset, asr_dataset, pacc_dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GTSRB_WaNetFrequency():\n",
    "    ## WaNet 1\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32),antialias=True),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    wanet = WaNet(\"/home/minzhou/public_html/backdoor_compet/base_line/checkpoint/WaNet_identity_grid.pth\", \"/home/minzhou/public_html/backdoor_compet/base_line/checkpoint/WaNet_noise_grid.pth\")\n",
    "    poison_method = ((wanet.img_poi, None), None)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/base_line/data/gtsrb.npy', test_transform, poison_method, 2)\n",
    "\n",
    "    ## Frequency 2\n",
    "    trigger_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "    noisy = trigger_transform(np.load('/home/minzhou/public_html/backdoor_compet/base_line/checkpoint/gtsrb_universal.npy')[0])\n",
    "    frequency_attack = Blended(noisy,clip_range = (-1,1), mode='torch')\n",
    "\n",
    "    poison_method = ((None, frequency_attack.img_poi), None)\n",
    "    _, _, asr_dataset2, pacc_dataset2 = get_dataset('/home/minzhou/public_html/backdoor_compet/base_line/data/gtsrb.npy', test_transform, poison_method, 13)\n",
    "    \n",
    "    \n",
    "    net = GoogLeNet()\n",
    "    net.load_state_dict(torch.load('/home/minzhou/public_html/backdoor_compet/base_line/checkpoint/gtsrb_googlenet_wantfrequency.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, (asr_dataset, asr_dataset2), (pacc_dataset, pacc_dataset2), net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''GoogLeNet with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n3x3red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n5x5red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1,y2,y3,y4], 1)\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes = 43):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
    "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pre_layers(x)\n",
    "        out = self.a3(out)\n",
    "        out = self.b3(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.a4(out)\n",
    "        out = self.b4(out)\n",
    "        out = self.c4(out)\n",
    "        out = self.d4(out)\n",
    "        out = self.e4(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.a5(out)\n",
    "        out = self.b5(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageNet_SRA():\n",
    "    ## blended sra\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32),antialias=True),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    trigger = np.array(iio.imread(\"/home/minzhou/public_html/backdoor_compet/Subnet-Replacement-Attack/triggers/hellokitty_224.png\")*0.2).astype(np.uint8)\n",
    "    blended = Blended(trigger,clip_range = (0,255), mode='np')\n",
    "    poison_method = ((blended.img_poi, None), None)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/imagenet100.npy', test_transform, poison_method, 7)\n",
    "    \n",
    "    \n",
    "    net = torchvision.models.vgg16_bn()\n",
    "    net.load_state_dict(torch.load('/home/minzhou/public_html/backdoor_compet/Subnet-Replacement-Attack/checkpoints/imagenet/poisoned_vgg16_tar7_blended.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Badnets_cifar10():\n",
    "    badnets = BadNets(size=4, position=27)\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "\n",
    "    poison_method = ((badnets.img_poi, None), None)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, 2)\n",
    "    \n",
    "    model = ResNet18()\n",
    "    model.load_state_dict(torch.load('/home/minzhou/public_html/datascan/poisoned_model/checkpoints/aug_cifar10_backdoor_0.05_resnet18_tar2.pth',map_location='cuda:0'))\n",
    "    model = model.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Blended_cifar10():\n",
    "    noisy = iio.imread('/home/minzhou/public_html/dataeval/poi_util_yi/Smooth_L0_L2_Blend_Trojan_PreActResNet/Smooth_L0_L2_Blend_Trojan_PreActResNet/triggers/blend.png')\n",
    "    blended = Blended(noisy,clip_range = (0,255), mode='np',img_size=32)\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "\n",
    "    poison_method = ((blended.img_poi, None), None)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, 2)\n",
    "    \n",
    "    model = ResNet18()\n",
    "    model.load_state_dict(torch.load('/home/minzhou/public_html/datascan/poisoned_model/checkpoints/aug_cifar10_blend_0.05_resnet18_tar2.pth',map_location='cuda:0'))\n",
    "    model = model.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIG_cifar10():\n",
    "    sig = SIG(size=32, delta = 20, f = 15)\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "\n",
    "    poison_method = ((sig.img_poi, None), None)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, 6)\n",
    "    \n",
    "    model = ResNet18()\n",
    "    model.load_state_dict(torch.load('/home/minzhou/public_html/backdoor_compet/base_line/checkpoint/cifar10_resnet18_sig.pth',map_location='cuda:0'))\n",
    "    model = model.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR10_WaNet():\n",
    "    ## WaNet 1\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    wanet = WaNet(\"/home/minzhou/public_html/datascan/BackdoorBox/ResNet-18_CIFAR-10_WaNet_identity_grid.pth\", \"/home/minzhou/public_html/datascan/BackdoorBox/ResNet-18_CIFAR-10_WaNet_noise_grid.pth\")\n",
    "    poison_method = ((wanet.img_poi, None), None)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, 2)\n",
    "    \n",
    "    \n",
    "    net = ResNet18()\n",
    "    net.load_state_dict(torch.load('/home/minzhou/public_html/datascan/BackdoorBox/experiments/ResNet-18_CIFAR-10_WaNet_2022-10-23_12:44:35/ckpt_epoch_200.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR10_LC():\n",
    "    ## WaNet 1\n",
    "\n",
    "    lc = LC()\n",
    "    poison_method = ((lc.img_poi, None), None)\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    \n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, 2)\n",
    "    \n",
    "    \n",
    "    net = ResNet18()\n",
    "    net.load_state_dict(torch.load('/home/minzhou/public_html/backdoor_compet/round2/checkpoint/ckpt_epoch_200_lc.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR10_ISSBA():\n",
    "    ## ISSBA\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    \n",
    "    poison_method = ((None, None), None)\n",
    "    val_dataset, test_dataset, _, _ = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, -1)\n",
    "    \n",
    "    secret = [1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]\n",
    "    issba = ISSBA(test_dataset, '/home/minzhou/public_html/backdoor_compet/round2/checkpoint/best_model.pth', secret)\n",
    "    asr_dataset, pacc_dataset = issba.get_dataset()\n",
    "    \n",
    "    net = GoogLeNet(num_classes=10)\n",
    "    net.load_state_dict(torch.load('/home/minzhou/public_html/backdoor_compet/round2/checkpoint/ckpt_epoch_200.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR10_CTRL():\n",
    "    ## SSL poison method, CTRL\n",
    "\n",
    "    ctrl = CTRL()\n",
    "    poison_method = ((ctrl.img_poi, None), None)\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    \n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('/home/minzhou/public_html/backdoor_compet/round1/data/cifar_10.npy', test_transform, poison_method, 2)\n",
    "    \n",
    "    net = ResNet18()\n",
    "    net.load_state_dict(torch.load('./checkpoints/simclr_ResNet18_ctrl.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR10_CTRL():\n",
    "    ## SSL poison method, CTRL\n",
    "\n",
    "    ctrl = CTRL()\n",
    "    poison_method = ((ctrl.img_poi, None), None)\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    \n",
    "    cifar_10_dataset = torchvision.datasets.CIFAR10('/home/minzhou/data', train=False, transform=None, download=False)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_torch_dataset(cifar_10_dataset, 500, test_transform, poison_method, 2)\n",
    "    \n",
    "    net = ResNet18()\n",
    "    net.load_state_dict(torch.load('./checkpoints/simclr_ResNet18_ctrl.pth',map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "    \n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "def clean_model(net, val_dataset):\n",
    "    import torch\n",
    "    net.eval()\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, num_workers=4, shuffle=True)\n",
    "    import timm\n",
    "    import torchvision\n",
    "    if isinstance(net, ResNet):\n",
    "        c = 0.2\n",
    "        a = 1.2\n",
    "        bs = 200\n",
    "        thr = 97\n",
    "        ep = 100\n",
    "        adjust = True\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([64, 1, 1]).to(device) + 6.0\n",
    "                self.clamp_w2 = torch.ones([64, 1, 1]).to(device) + 6.0\n",
    "                self.clamp_w3 = torch.ones([128, 1, 1]).to(device) + 6.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "\n",
    "            def forward(self, x):\n",
    "                out = self.model.conv1(x)\n",
    "                out = torch.min(out, 2 * self.clamp_w1 - out)\n",
    "                out = torch.nn.functional.relu(self.model.bn1(out))\n",
    "                out = self.model.layer1(out)\n",
    "                out = torch.min(out, 2 * self.clamp_w2 - out)\n",
    "                out = self.model.layer2(out)\n",
    "                out = torch.min(out, 2 * self.clamp_w3 - out)\n",
    "                out = self.model.layer3(out)\n",
    "                out = self.model.layer4(out)\n",
    "                out = torch.nn.functional.avg_pool2d(out, 4)\n",
    "                out = out.view(out.size(0), -1)\n",
    "                out = self.model.linear(out)\n",
    "                return out\n",
    "    elif isinstance(net, timm.models.vision_transformer.VisionTransformer):\n",
    "        c = 0.01\n",
    "        a = 1.2\n",
    "        bs = 32\n",
    "        thr = 99\n",
    "        ep = 100\n",
    "        adjust = False\n",
    "        from timm.models.vision_transformer import checkpoint_seq\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([196, 192]).to(device) + 17.0\n",
    "                self.clamp_w2 = torch.ones([1, 192]).to(device) + 7.0\n",
    "                self.clamp_w3 = torch.ones([1, 192]).to(device) + 7.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "\n",
    "            def forward(self, x):\n",
    "                out = self.model.patch_embed(x)\n",
    "                out = torch.min(out, 2 * self.clamp_w1 - out)\n",
    "                out = self.model._pos_embed(out)\n",
    "\n",
    "                out = self.model.norm_pre(out)\n",
    "\n",
    "                for idx, layer in enumerate(self.model.blocks):\n",
    "                    out = layer(out)\n",
    "\n",
    "                out = self.model.norm(out)\n",
    "                out = self.model.forward_head(out)\n",
    "                return out\n",
    "    elif isinstance(net, torchvision.models.resnet.ResNet):\n",
    "        c = 0.2\n",
    "        a = 1.2\n",
    "        bs = 200\n",
    "        thr = 99.5\n",
    "        ep = 100\n",
    "        adjust = False\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([64, 1, 1]).to(device) + 6.0\n",
    "                self.clamp_w2 = torch.ones([64, 1, 1]).to(device) + 6.0\n",
    "                self.clamp_w3 = torch.ones([128, 1, 1]).to(device) + 6.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "\n",
    "            def forward(self, x):\n",
    "                out = self.model.conv1(x)\n",
    "                out = torch.min(out, 2 * self.clamp_w1 - out)\n",
    "                out = torch.nn.functional.relu(self.model.bn1(out))\n",
    "                out = self.model.maxpool(out)\n",
    "                out = self.model.layer1(out)\n",
    "                out = torch.min(out, 2 * self.clamp_w2 - out)\n",
    "                out = self.model.layer2(out)\n",
    "                out = torch.min(out, 2 * self.clamp_w3 - out)\n",
    "                out = self.model.layer3(out)\n",
    "                out = self.model.layer4(out)\n",
    "                out = self.model.avgpool(out)\n",
    "                out = out.view(out.size(0), -1)\n",
    "                out = self.model.fc(out)\n",
    "                return out\n",
    "    elif isinstance(net, GoogLeNet):\n",
    "        c = 0.2\n",
    "        a = 1.2\n",
    "        bs = 200\n",
    "        thr = 97\n",
    "        ep = 100\n",
    "        adjust = True\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([192, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w2 = torch.ones([256, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w3 = torch.ones([480, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "\n",
    "            def forward(self, x):\n",
    "                out = x\n",
    "                for idx, layer in enumerate(self.model.pre_layers):\n",
    "                    out = layer(out)\n",
    "                    if idx == 0:\n",
    "                        out = torch.min(out, 2 * self.clamp_w1 - out)\n",
    "                out = self.model.a3(out)\n",
    "                out = torch.min(out, 2 * self.clamp_w2 - out)\n",
    "                out = self.model.b3(out)\n",
    "                out = torch.min(out, 2 * self.clamp_w3 - out)\n",
    "                out = self.model.maxpool(out)\n",
    "                out = self.model.a4(out)\n",
    "                out = self.model.b4(out)\n",
    "                out = self.model.c4(out)\n",
    "                out = self.model.d4(out)\n",
    "                out = self.model.e4(out)\n",
    "                out = self.model.maxpool(out)\n",
    "                out = self.model.a5(out)\n",
    "                out = self.model.b5(out)\n",
    "                out = self.model.avgpool(out)\n",
    "                out = out.view(out.size(0), -1)\n",
    "                out = self.model.linear(out)\n",
    "                return out\n",
    "    elif isinstance(net, torchvision.models.GoogLeNet):\n",
    "        c = 0.2\n",
    "        a = 1.2\n",
    "        bs = 32\n",
    "        thr = 99\n",
    "        ep = 100\n",
    "        adjust = False\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([64, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w2 = torch.ones([64, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w3 = torch.ones([192, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "\n",
    "            def forward(self, x):\n",
    "                # N x 3 x 224 x 224\n",
    "                x = self.conv1(x)\n",
    "                # N x 64 x 112 x 112\n",
    "                x = torch.min(x, 2 * self.clamp_w1 - x)\n",
    "                x = self.maxpool1(x)\n",
    "                # N x 64 x 56 x 56\n",
    "                x = self.conv2(x)\n",
    "                # N x 64 x 56 x 56\n",
    "                x = torch.min(x, 2 * self.clamp_w2 - x)\n",
    "                x = self.conv3(x)\n",
    "                # N x 192 x 56 x 56\n",
    "                x = torch.min(x, 2 * self.clamp_w3 - x)\n",
    "                x = self.maxpool2(x)\n",
    "\n",
    "                # N x 192 x 28 x 28\n",
    "                x = self.inception3a(x)\n",
    "                # N x 256 x 28 x 28\n",
    "                x = self.inception3b(x)\n",
    "                # N x 480 x 28 x 28\n",
    "                x = self.maxpool3(x)\n",
    "                # N x 480 x 14 x 14\n",
    "                x = self.inception4a(x)\n",
    "                # N x 512 x 14 x 14\n",
    "                aux1 = None\n",
    "                if self.aux1 is not None:\n",
    "                    if self.training:\n",
    "                        aux1 = self.aux1(x)\n",
    "\n",
    "                x = self.inception4b(x)\n",
    "                # N x 512 x 14 x 14\n",
    "                x = self.inception4c(x)\n",
    "                # N x 512 x 14 x 14\n",
    "                x = self.inception4d(x)\n",
    "                # N x 528 x 14 x 14\n",
    "                aux2 = None\n",
    "                if self.aux2 is not None:\n",
    "                    if self.training:\n",
    "                        aux2 = self.aux2(x)\n",
    "\n",
    "                x = self.inception4e(x)\n",
    "                # N x 832 x 14 x 14\n",
    "                x = self.maxpool4(x)\n",
    "                # N x 832 x 7 x 7\n",
    "                x = self.inception5a(x)\n",
    "                # N x 832 x 7 x 7\n",
    "                x = self.inception5b(x)\n",
    "                # N x 1024 x 7 x 7\n",
    "\n",
    "                x = self.avgpool(x)\n",
    "                # N x 1024 x 1 x 1\n",
    "                x = torch.flatten(x, 1)\n",
    "                # N x 1024\n",
    "                x = self.dropout(x)\n",
    "                x = self.fc(x)\n",
    "                # N x 1000 (num_classes)\n",
    "                return x, aux2, aux1\n",
    "    elif isinstance(net, torchvision.models.vgg.VGG):\n",
    "        c = 0.2\n",
    "        a = 1.2\n",
    "        bs = 32\n",
    "        thr = 99\n",
    "        ep = 100\n",
    "        adjust = False\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([64, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w2 = torch.ones([64, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w3 = torch.ones([128, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "                self.clamp = [self.clamp_w1, self.clamp_w2, self.clamp_w3]\n",
    "\n",
    "            def forward(self, x):\n",
    "                out = x\n",
    "                for idx, layer in enumerate(self.model.features):\n",
    "                    out = layer(out)\n",
    "                    if idx == 0:\n",
    "                        out = torch.min(out, 2 * self.clamp_w1 - out)\n",
    "\n",
    "                    if idx == 3:\n",
    "                        out = torch.min(out, 2 * self.clamp_w2 - out)\n",
    "                    if idx == 7:\n",
    "                        out = torch.min(out, 2 * self.clamp_w3 - out)\n",
    "                out = out.view(out.size(0), -1)\n",
    "                out = self.model.classifier(out)\n",
    "                return out\n",
    "    else:\n",
    "        c = 0.2\n",
    "        a = 1.2\n",
    "        bs = 200\n",
    "        thr = 97\n",
    "        ep = 100\n",
    "        adjust = True\n",
    "        class CleanNet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(CleanNet, self).__init__()\n",
    "                self.model = net\n",
    "                self.clamp_w1 = torch.ones([64, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w2 = torch.ones([64, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w3 = torch.ones([128, 1, 1]).to(device) + 7.0\n",
    "                self.clamp_w1.requires_grad = True\n",
    "                self.clamp_w2.requires_grad = True\n",
    "                self.clamp_w3.requires_grad = True\n",
    "\n",
    "            def forward(self, x):\n",
    "                out = x\n",
    "                for idx, layer in enumerate(self.model.features):\n",
    "                    out = layer(out)\n",
    "                    if idx == 0:\n",
    "                        out = torch.min(out, 2 * self.clamp_w1 - out)\n",
    "                    if idx == 3:\n",
    "                        out = torch.min(out, 2 * self.clamp_w2 - out)\n",
    "\n",
    "                    if idx == 7:\n",
    "                        out = torch.min(out, 2 * self.clamp_w3 - out)\n",
    "\n",
    "                out = out.view(out.size(0), -1)\n",
    "                out = self.model.classifier(out)\n",
    "                return out\n",
    "\n",
    "    network = CleanNet()\n",
    "\n",
    "    network.to(device)\n",
    "    correct_idx = []\n",
    "    val_dataset = val_dataloader.dataset\n",
    "    for i in range(val_dataset.__len__()):\n",
    "        image, label = val_dataset.__getitem__(i)\n",
    "        image = image.to(device).unsqueeze(0)\n",
    "        out = network.model(image)\n",
    "        _, predicted = out.max(1)\n",
    "        if predicted.item() == label:\n",
    "            correct_idx.append(i)\n",
    "    # print(len(correct_idx))\n",
    "    val_dataset = torch.utils.data.Subset(val_dataset, correct_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs, shuffle=True, num_workers=2)\n",
    "    optimizer = torch.optim.Adam([network.clamp_w1,\n",
    "                                  network.clamp_w2,\n",
    "                                  network.clamp_w3],\n",
    "                                 lr=0.1)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(bs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for idx, (images, labels) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            ref_out = network.model(images)\n",
    "            outputs = network(images)\n",
    "            loss1 = mse(outputs, ref_out)\n",
    "            loss2 = torch.norm(network.clamp_w1) \\\n",
    "                    + torch.norm(network.clamp_w2) \\\n",
    "                    + torch.norm(network.clamp_w3)\n",
    "            # print(network.clamp_w1)\n",
    "            loss = loss1 + c * loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        # print(acc)\n",
    "        if epoch > 10 and epoch % 10 == 0:\n",
    "            if acc >= thr:\n",
    "                c *= a\n",
    "            else:\n",
    "                c /= a\n",
    "    class_dim = outputs.size()[1]\n",
    "    min_lim = torch.zeros([class_dim]).to(device)\n",
    "    max_lim = torch.zeros([class_dim]).to(device)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "    for idx, (images, labels) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        ref_out = network.model(images).detach()\n",
    "        outputs = network(images).detach()\n",
    "        diff = outputs - ref_out\n",
    "        max_lim = torch.max(torch.max(diff, dim=0)[0], max_lim)\n",
    "        min_lim = torch.min(torch.min(diff, dim=0)[0], min_lim)\n",
    "\n",
    "    class FinalNet(nn.Module):\n",
    "        def __init__(self, network, max_lim, min_lim):\n",
    "            super(FinalNet, self).__init__()\n",
    "            self.network = network\n",
    "            self.max_lim = max_lim\n",
    "            self.min_lim = min_lim\n",
    "\n",
    "        def forward(self, x):\n",
    "            new_x = self.network(x)\n",
    "            old_x = self.network.model(x)\n",
    "            diff = new_x - old_x\n",
    "            if adjust:\n",
    "                final_x = new_x + 20 * diff * (diff < 1 * self.min_lim).float()\n",
    "            else:\n",
    "                final_x = new_x + 20 * diff * (diff < 1.5 * self.min_lim).float()\n",
    "            return final_x\n",
    "    return FinalNet(network, max_lim, min_lim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_defense(defense_method, attack_method, pre_eval = True, post_eval=True):\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset, model = attack_method()\n",
    "    if pre_eval:\n",
    "        print(\"Result for model before defense\")\n",
    "        if test_dataset is not None:\n",
    "            print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "        \n",
    "        if asr_dataset is not None:\n",
    "            if isinstance(asr_dataset,tuple):\n",
    "                for i in range(len(asr_dataset)):\n",
    "                    print('ASR for attack '+ str(i) +': %.3f%%'  % (100 * get_results(model, asr_dataset[i])))\n",
    "            else:\n",
    "                print('ASR: %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "        \n",
    "        if pacc_dataset is not None:\n",
    "            if isinstance(pacc_dataset,tuple):\n",
    "                for i in range(len(pacc_dataset)):\n",
    "                    print('PACC for attack '+ str(i) +': %.3f%%' % (100 * get_results(model, pacc_dataset[i])))\n",
    "            else:\n",
    "                print('PACC: %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "    cleaned_model = defense_method(model, val_dataset)\n",
    "    # Print the model evaluation information after defense\n",
    "    if post_eval:\n",
    "        print(\"Result for model after defense\")\n",
    "        if test_dataset is not None:\n",
    "            print('ACC：%.3f%%' % (100 * get_results(cleaned_model, test_dataset)))\n",
    "        \n",
    "        if asr_dataset is not None:\n",
    "            if isinstance(asr_dataset,tuple):\n",
    "                for i in range(len(asr_dataset)):\n",
    "                    print('ASR for attack '+ str(i) +': %.3f%%'  % (100 * get_results(cleaned_model, asr_dataset[i])))\n",
    "            else:\n",
    "                print('ASR: %.3f%%' % (100 * get_results(cleaned_model, asr_dataset)))\n",
    "        \n",
    "        if pacc_dataset is not None:\n",
    "            if isinstance(pacc_dataset,tuple):\n",
    "                for i in range(len(pacc_dataset)):\n",
    "                    print('PACC for attack '+ str(i) +': %.3f%%' % (100 * get_results(cleaned_model, pacc_dataset[i])))\n",
    "            else:\n",
    "                print('PACC: %.3f%%' % (100 * get_results(cleaned_model, pacc_dataset)))\n",
    "    return cleaned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_defense_list(defense_method, attack_list, pre_eval = True, post_eval=True):\n",
    "    for attack_method in attack_list:\n",
    "        test_defense(defense_method, attack_method, pre_eval = pre_eval, post_eval = post_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_list = [PubFig_all2all, GTSRB_WaNetFrequency, ImageNet_SRA, Badnets_cifar10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for model before defense\n",
      "ACC：86.022%\n",
      "ASR: 78.430%\n",
      "PACC: 1.035%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_defense_list(clean_model, attack_list)\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mtest_defense_list\u001b[0;34m(defense_method, attack_list, pre_eval, post_eval)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_defense_list\u001b[39m(defense_method, attack_list, pre_eval \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, post_eval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m attack_method \u001b[39min\u001b[39;00m attack_list:\n\u001b[0;32m----> 3\u001b[0m         test_defense(defense_method, attack_method, pre_eval \u001b[39m=\u001b[39;49m pre_eval, post_eval \u001b[39m=\u001b[39;49m post_eval)\n",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m, in \u001b[0;36mtest_defense\u001b[0;34m(defense_method, attack_method, pre_eval, post_eval)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPACC: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m get_results(model, pacc_dataset)))\n\u001b[0;32m---> 21\u001b[0m cleaned_model \u001b[39m=\u001b[39m defense_method(model, val_dataset)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Print the model evaluation information after defense\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m post_eval:\n",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m, in \u001b[0;36mclean_model\u001b[0;34m(net, val_dataset)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtimm\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(net, ResNet18):\n\u001b[1;32m      9\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[1;32m     10\u001b[0m     a \u001b[39m=\u001b[39m \u001b[39m1.2\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "test_defense_list(clean_model, attack_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
